using Microsoft.Extensions.DependencyInjection;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.Agents;
using Microsoft.SemanticKernel.Agents.Chat;
using Microsoft.SemanticKernel.ChatCompletion;
using Microsoft.SemanticKernel.Connectors.Google;
using Microsoft.SemanticKernel.Connectors.OpenAI;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;
using Serilog;
using Serilog.Events;


public static partial class Algos
{
    public static void AddConsoleLogger(string? logName)
    {
        var serilogLogger = new LoggerConfiguration()
            .Enrich.FromLogContext()
            .MinimumLevel.Verbose()
            .MinimumLevel.Override("Microsoft", LogEventLevel.Warning)
            .MinimumLevel.Override("System", LogEventLevel.Warning)
            .WriteTo.Console(
                restrictedToMinimumLevel: LogEventLevel.Information,
                outputTemplate: "[{Timestamp:HH:mm:ss} {Level:u3}] {Message:lj}{NewLine}{Exception}")
            .WriteTo.File(
                path: logName ?? "log.txt",
                restrictedToMinimumLevel: LogEventLevel.Information,
                rollingInterval: RollingInterval.Infinite,
                rollOnFileSizeLimit: true,
                fileSizeLimitBytes: 100 * 1024 * 1024, // 100 MB
                retainedFileCountLimit: 5)
            .CreateLogger();

        Log.Logger = serilogLogger;
        Log.Information("Serilog configured.");
    }
}

class Program
{
    public static async Task<string> InvokeAgentMethod(ChatCompletionAgent agent, ChatHistory history)
    {
        var initialMessages = new List<ChatMessageContent>();
        await foreach (var msg in agent.InvokeAsync(history))
        {
            initialMessages.Add(msg);
        }
        return initialMessages.LastOrDefault()?.Content ?? "";
    }

    static async Task Main(string[] args)
    {
        Algos.AddConsoleLogger("MultiAgentThinkGroupLog.txt");

        // Load keys
        var openAIKey = Environment.GetEnvironmentVariable("OPENAI_API_KEY") ?? throw new InvalidOperationException("OPENAI_API_KEY not set.");
        var googleKey = Environment.GetEnvironmentVariable("GOOGLE_API_KEY") ?? throw new InvalidOperationException("GOOGLE_API_KEY not set.");
        var grokKey = Environment.GetEnvironmentVariable("GROK_API_KEY") ?? throw new InvalidOperationException("GROK_API_KEY not set.");

        // Kernels for each LLM
        var grokBuilder = Kernel.CreateBuilder();
        grokBuilder.Services.AddSingleton<IChatCompletionService>(new GrokCompletionService(grokKey));
        var grokKernel = grokBuilder.Build();

        var chatGPTKernel = Kernel.CreateBuilder().AddOpenAIChatCompletion("gpt-5.1", openAIKey).Build();
        var geminiKernel = Kernel.CreateBuilder().AddGoogleAIGeminiChatCompletion("gemini-3-pro-preview", googleKey).Build();

        // chain instructions there are for chain of thought models like Grok where the CoT is actually proprietary and not available.
        var generateChainInstructions = "First, generate your initial response to the query by breaking down your answer into clear, sequential steps. ";
        // non-chain instructions are for non-chain of thought models like ChatGPT and Gemini where the CoT is just something generated by the model when asked.
        var generateNonChainInstructions = "First, generate your initial response to the query with step-by-step reasoning. ";
        // additional instructions for group chat evaluation and refinement
        var additionalInstructions = "In group chat, respond only on your turn. " +
            "Evaluate others' responses (quality 1-10, veracity 1-10, suggestions). " +
            "Analyze CoT steps for validity; if discrepancies exist, provide rationale and propose resolution toward consensus. " +
            "Propose refinements. " +
            "Do not simulate others. " +
            "End ONLY when all agree on consensus with 'TERMINATE'.";

        // Agents with tweaked instructions: No simulation of others, explicit multi-turn, terminate only on group consensus
        var grokAgent = new ChatCompletionAgent
        {
            Kernel = grokKernel,
            Name = "GrokAgent",
            Instructions = generateChainInstructions + additionalInstructions
        };
        var chatGPTAgent = new ChatCompletionAgent
        {
            Kernel = chatGPTKernel,
            Name = "ChatGPTAgent",
            Instructions = generateNonChainInstructions + additionalInstructions
        };
        var geminiAgent = new ChatCompletionAgent
        {
            Kernel = geminiKernel,
            Name = "GeminiAgent",
            Instructions = generateNonChainInstructions + additionalInstructions
        };

        var consolidatorAgent = new ChatCompletionAgent
        {
            Kernel = grokKernel,
            Name = "Consolidator",
            Instructions = "Review the group chat history, including initial responses and evaluations. " +
            "Highlight additional relevant conclusions from debates. " +
            "Merge into a single, improved output with additional conclusions, resolving conflicts, and citing sources. " +
            "Break down your merging process into sequential steps."
        };

        // Sample Query (or use a simpler test query like "What is 2+2?" for debugging)
        var query = "How do I get my home-made pizzas to taste better?";  // Or test: "What is 2+2? Explain step by step."

        // Generate initial CoT responses from each agent in parallel
        var initialHistory = new ChatHistory();
        initialHistory.AddUserMessage(query);

        // Start generation for each agent
        var grokTask = Task.Run(async () => { return await InvokeAgentMethod(grokAgent, initialHistory); } );
        var chatGPTTask = Task.Run(async () => { return await InvokeAgentMethod(chatGPTAgent, initialHistory); });
        var geminiTask = Task.Run(async () => { return await InvokeAgentMethod(geminiAgent, initialHistory); });

        // Collect initial messages
        var grokInitialContent = await grokTask;
        var chatGPTInitialContent = await chatGPTTask;
        var geminiInitialContent = await geminiTask;

        Log.Information($"Grok Initial: {grokInitialContent}");
        Log.Information($"ChatGPT Initial: {chatGPTInitialContent}");
        Log.Information($"Gemini Initial: {geminiInitialContent}");

        // Define Termination Function (adjusted to check if ALL recent messages include 'TERMINATE')
        var terminationFunction = KernelFunctionFactory.CreateFromPrompt(
            "Review the last three agent messages: {{$input}}\n" +
            "If ALL contain the word 'TERMINATE', output 'true'; otherwise, output 'false'.",
            functionName: "ShouldTerminate"
        );

        var terminationStrategy = new KernelFunctionTerminationStrategy(terminationFunction, chatGPTKernel)
        {
            MaximumIterations = 15,  // Increased for more rounds (5 rounds x 3 agents)
            Arguments = new KernelArguments { ["input"] = "{{$history.LastN(3)}}" }  // Custom to check last 3
        };

        var selectionStrategy = new SequentialSelectionStrategy();  // Ensures forced sequential turns

        // Group Chat for Evaluation/Refinement
        var groupChat = new AgentGroupChat(grokAgent, chatGPTAgent, geminiAgent)
        {
            ExecutionSettings = new AgentGroupChatSettings
            {
                TerminationStrategy = terminationStrategy,
                SelectionStrategy = selectionStrategy
            }
        };

        // Seed group chat with initial responses
        groupChat.AddChatMessage(new ChatMessageContent(AuthorRole.User, query));
        groupChat.AddChatMessage(new ChatMessageContent(AuthorRole.Assistant, $"Grok Initial: {grokInitialContent}", grokAgent.Name));
        groupChat.AddChatMessage(new ChatMessageContent(AuthorRole.Assistant, $"ChatGPT Initial: {chatGPTInitialContent}", chatGPTAgent.Name));
        groupChat.AddChatMessage(new ChatMessageContent(AuthorRole.Assistant, $"Gemini Initial: {geminiInitialContent}", geminiAgent.Name));
        groupChat.AddChatMessage(new ChatMessageContent(AuthorRole.User, "Now evaluate each other's CoT responses, suggest improvements, refine collaboratively, and reach consensus on a merged output. Take turns: Grok first, then ChatGPT, then Gemini. Continue until all agree."));

        // Invoke Group Chat (Iterations) with debug logging
        Log.Information("Group Chat Evaluations:");
        int turn = 0;
        await foreach (var message in groupChat.InvokeAsync())
        {
            turn++;
            Log.Information($"Turn {turn} - {message.AuthorName}: {message.Content}");
        }

        // Retrieve chat history
        var historyMessages = new List<ChatMessageContent>();
        await foreach (var msg in groupChat.GetChatMessagesAsync())
        {
            historyMessages.Add(msg);
        }

        // Check history length and summarize if too long (to avoid truncation)
        if (historyMessages.Count > 50)  // Arbitrary threshold; adjust based on token limits
        {
            var summarizer = new ChatCompletionAgent
            {
                Kernel = grokKernel,
                Name = "Summarizer",
                Instructions = "Summarize the chat history concisely, preserving key CoT, evaluations, and proposals."
            };
            var summaryInput = new ChatHistory(historyMessages);
            var summaryMessages = new List<ChatMessageContent>();
            await foreach (var msg in summarizer.InvokeAsync(summaryInput))
            {
                summaryMessages.Add(msg);
            }
            historyMessages = summaryMessages;  // Replace with summary for consolidator
            Log.Warning("History summarized due to length.");
        }

        // Consolidate
        var finalInput = new ChatHistory(historyMessages);
        var finalOutputs = new List<ChatMessageContent>();
        await foreach (var msg in consolidatorAgent.InvokeAsync(finalInput))
        {
            finalOutputs.Add(msg);
        }
        if (finalOutputs.Count > 0)
        {
            Log.Information("Final Output: {content}", finalOutputs.Last().Content);
        }
    }
}